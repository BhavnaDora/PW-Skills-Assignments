{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931e465d-e1d7-4d7b-964b-c662a16bacbe",
   "metadata": {},
   "source": [
    "#### (1)-\n",
    "##### Assumptions in ANOVA-\n",
    "##### 1- Normality of sampling distribution of mean\n",
    "##### 2- Absence of outliers\n",
    "##### 3- Homogeneity of variance\n",
    "##### 4- Samples are independent and random\n",
    "##### The presence of outliers can also cause problems. In addition, we need to make sure that the F statistic is well behaved. In particular, the F statistic is relatively robust to violations of normality provided:\n",
    "##### The populations are symmetrical and uni-modal.\n",
    "##### The sample sizes for the groups are equal and greater than 10\n",
    "##### In general, as long as the sample sizes are equal (called a balanced model) and sufficiently large, the normality assumption can be violated provided the samples are symmetrical or at least similar in shape (e.g. all are negatively skewed). The F statistic is not so robust to violations of homogeneity of variances. A rule of thumb for balanced models is that if the ratio of the largest variance to smallest variance is less than 3 or 4, the F-test will be valid. If the sample sizes are unequal then smaller differences in variances can invalidate the F-test. Much more attention needs to be paid to unequal variances than to non-normality of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53864225-396e-4b14-b6b4-90fa3d174a5e",
   "metadata": {},
   "source": [
    "#### (2)-\n",
    "##### 3 types of ANOVA are-\n",
    "##### 1- One way ANOVA- When we have one factor with atleast 2 levels and these levels are independent then we use one way ANOVA\n",
    "##### 2- Repeated measures ANOVA- When we have one factor with atleast 2 levels and these levels are dependent, we use repeated measures ANOVA. \n",
    "##### 3- Factorial ANOVA- When we have 2 or more factors each having atleast 2 levels. These levels can be independent or dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239913d1-91bd-4bd7-84b7-3019032d28e2",
   "metadata": {},
   "source": [
    "#### (3)-\n",
    "##### Partitioning of variance in ANOVA is the hypothesis testing. ANOVA is based on the law of total variance, where the observed variance in a particular variable is partitioned into components attributable to different sources of variation. With the help of such a partitioning, some testing of hypothesis may be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b6e99-eba3-45f8-9f24-d09147547141",
   "metadata": {},
   "source": [
    "#### (4)-\n",
    "##### Total sum of squares (SST)- The sum of squared differences between individual data points (yi) and the mean of the response variable (ybar).\n",
    "##### Explained sum of squares (SSE)- The sum of squared differences between predicted data points (ŷi) and the mean of the response variable(ybar).\n",
    "##### Residual sum of squares (SSR)- The sum of squared differences between predicted data points (ŷi) and observed data points (yi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e918446f-6be9-4cd4-b6e2-bb1d83dd2c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hours  score\n",
       "0      1     68\n",
       "1      1     76\n",
       "2      1     74\n",
       "3      2     80\n",
       "4      2     76"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame({'hours': [1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
    "                             3, 4, 4, 4, 5, 5, 6, 7, 7, 8],\n",
    "                   'score': [68, 76, 74, 80, 76, 78, 81, 84, 86, 83,\n",
    "                             88, 85, 89, 94, 93, 94, 96, 89, 92, 97]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d0efd8-5ad1-4d35-ba68-0e8790273cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# independent variable-\n",
    "x= df[\"hours\"]\n",
    "\n",
    "# dependent variable-\n",
    "y= df[\"score\"]\n",
    "\n",
    "# adding constant-\n",
    "x= sm.add_constant(x)\n",
    "\n",
    "# fit linear regression model-\n",
    "model= sm.OLS(y,x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be22f4f3-8b79-4590-a94f-3c1d3e25544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE= 917.4751152073725\n",
      "SSR= 331.07488479262696\n",
      "SST= 1248.5499999999995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate SSE\n",
    "sse= np.sum((model.fittedvalues - df.score.mean())**2)\n",
    "print(\"SSE=\", sse)\n",
    "\n",
    "# calculate SSR-\n",
    "ssr= np.sum((model.fittedvalues- df.score)**2)\n",
    "print(\"SSR=\", ssr)\n",
    "\n",
    "#calculate SST-\n",
    "sst= ssr+sse\n",
    "print(\"SST=\", sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cefdb3-5270-42ff-91c4-103ec3129a54",
   "metadata": {},
   "source": [
    "#### (5)-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c13f712-6c4e-4570-b759-1a53c8f3be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(Fertilizer)               1.0   0.033333  0.033333  0.012069  0.913305\n",
      "C(Watering)                 1.0   0.000369  0.000369  0.000133  0.990865\n",
      "C(Fertilizer):C(Watering)   1.0   0.040866  0.040866  0.014796  0.904053\n",
      "Residual                   28.0  77.333333  2.761905       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "  \n",
    "# Create a dataframe\n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'height': [14, 16, 15, 15, 16, 13, 12, 11,\n",
    "                                     14, 15, 16, 16, 17, 18, 14, 13, \n",
    "                                     14, 14, 14, 15, 16, 16, 17, 18,\n",
    "                                     14, 13, 14, 14, 14, 15]})\n",
    "  \n",
    "# Performing two-way ANOVA\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) +\\\n",
    "C(Fertilizer):C(Watering)',\n",
    "            data=dataframe).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "  \n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274b697-6e80-426e-89cd-99f898276303",
   "metadata": {},
   "source": [
    "#### (6)-\n",
    "##### If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is at least one significant difference between the means of the groups being compared. The F-statistic tells us the ratio of the variance between the groups to the variance within the groups. A larger F-statistic indicates a greater difference between the group means compared to the variation within the groups. The p-value tells us the probability of obtaining a result as extreme as the observed result if there were no true differences between the groups.\n",
    "##### With a p-value of 0.02, we can interpret this result as follows: if there were no true differences between the groups, we would only expect to obtain a result as extreme as an F-statistic of 5.23 or higher by chance 2% of the time. Therefore, we reject the null hypothesis (that there are no true differences between the groups) and conclude that there is sufficient evidence to suggest that at least one of the group means is different from the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59240e92-109b-406a-946d-710d2a9c6862",
   "metadata": {},
   "source": [
    "#### (7)-\n",
    "##### In repeated measures ANOVA, the missing data is handled by listwise deletion. The problem is that repeated measures ANOVA treats each measurement as a separate variable. Because it uses listwise deletion, if one measurement is missing, the entire case gets dropped. What to use instead: Marginal and mixed models treat each occasion as a different observation of the same variable. So you may lose the measurement with missing data, but not all other responses from the same subject.\n",
    "##### One of the most effective ways of dealing with missing data is multiple imputation (MI). Using MI, we can create multiple plausible replacements of the missing data, given what we have observed and a statistical model (the imputation model). In the ANOVA, using MI has the additional benefit that it allows taking covariates into account that are relevant for the missing data but not for the analysis. Running MI consists of three steps. First, the missing data are imputed multiple times. Second, the imputed data sets are analyzed separately. Third, the parameter estimates and hypothesis tests are pooled to form a final set of estimates and inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bbd3ee-ef55-4d17-8d77-8490e8a065a0",
   "metadata": {},
   "source": [
    "#### (8)-\n",
    "##### ANOVA test results don’t map out which groups are different from other groups- if we can reject the null hypothesis, we only know that not all of the means are equal. Sometimes we really need to know which groups are significantly different from other groups! To compare group means, we need to perform post hoc tests, also known as multiple comparisons. These post hoc tests also control the experiment wise error rate- which is the probability of making at least one Type I error (false positive) across all the pairwise comparisons.\n",
    "\n",
    "##### 1) Tukey's HSD (honestly significant difference) test: This test is a conservative post-hoc test that is commonly used when the sample sizes are equal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Tukey's HSD test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D.\n",
    "\n",
    "##### 2) Bonferroni correction: This test is a simple and commonly used method to adjust the significance level for each pairwise comparison. It divides the significance level (usually 0.05) by the number of comparisons being made. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use the Bonferroni correction to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B, group C, and group D, we can conclude that group A is significantly different from all the other groups.\n",
    "\n",
    "##### 3) Dunnett's test: This test is used when we have one control group and several treatment groups. It compares each treatment group to the control group, while controlling for the overall familywise error rate. For example, if we have one control group and three treatment groups (A, B, C), and the overall ANOVA result is significant, we might use Dunnett's test to determine which specific treatment groups differ from the control group. If the test shows that group A is significantly different from the control group, but groups B and C are not significantly different from the control group, we can conclude that group A is significantly different from the control group, but groups B and C are not.\n",
    "\n",
    "##### 4) Scheffe's test: This test is a conservative post-hoc test that is used when the sample sizes are unequal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Scheffe's test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8861a86-87e8-4f7a-8954-431496c55601",
   "metadata": {},
   "source": [
    "#### (9)-\n",
    "##### Null hypothesis(H0)- mean weight loss of the 3 diets are same.\n",
    "##### Alternate hypothesis(H1)- atleast one of the means is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07994d7-6de4-4652-8e07-d534a44e83c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f statistic value is 81.90624741827499\n",
      "p value is 4.816543489094047e-16\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "#sample data-\n",
    "diet_A= [4.2, 5.1, 3.7, 6.2, 4.9, 2.8, 5.4, 4.7, 3.9, 4.1, 3.3, 5.5, 4.8, 5.3, 3.9, 6.1]\n",
    "diet_B= [2.4, 2.0, 2.8, 2.2, 2.1, 2.6, 2.7, 1.6, 2.4, 2.9, 3.0, 1.8, 2.1, 2.3, 2.6, 4.7, 3.5]\n",
    "diet_C= [1.3, 0.9, 1.1, 1.6, 1.4, 1.8, 1.2, 1.5, 2.0, 1.4, 1.7, 1.3, 1.9, 1.0, 1.6, 1.2, 1.8]\n",
    "\n",
    "f_stats, p_value= f_oneway(diet_A, diet_B, diet_C)\n",
    "print(\"f statistic value is\", f_stats)\n",
    "print(\"p value is\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79133a57-81b8-46a6-a74a-a80f75a525ee",
   "metadata": {},
   "source": [
    "#### (10)-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c02e6bb-1957-4097-8447-35fc1bd810ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data example :\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "**********************************************************\n",
      "\n",
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  204.881181  102.440590  18.135666   \n",
      "C(Experience)               1.0  165.079097  165.079097  29.224933   \n",
      "C(Software):C(Experience)   2.0   17.481552    8.740776   1.547431   \n",
      "Residual                   56.0  316.319953    5.648571        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.460472e-07  \n",
      "C(Experience)              1.375177e-06  \n",
      "C(Software):C(Experience)  2.217544e-01  \n",
      "Residual                            NaN  \n",
      "\n",
      "\n",
      "Conclusion: There is a significant main effect of software.\n",
      "Conclusion: There is a significant main effect of experience.\n",
      "Conclusion: There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "    'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Print the simulated data head \n",
    "print('Simulated Data example :')\n",
    "print(data.head())\n",
    "\n",
    "print('\\n**********************************************************\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effect\n",
    "print(table)\n",
    "print('\\n')\n",
    "if table['PR(>F)'][0] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of software.\")\n",
    "\n",
    "if table['PR(>F)'][1] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of experience.\")\n",
    "\n",
    "if table['PR(>F)'][2] < alpha:\n",
    "    print(\"Conclusion: There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant interaction effect between software and experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53021adc-4a4f-40f0-b375-127a59622db3",
   "metadata": {},
   "source": [
    "#### (11)-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53896320-d989-481d-9b3c-adf3c61b46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated data for test_scores:\n",
      "   test_score    group\n",
      "0   70.079124  control\n",
      "1   70.780965  control\n",
      "2   68.814563  control\n",
      "3   69.387097  control\n",
      "4   66.185102  control\n",
      "\n",
      "************************\n",
      "\n",
      "t-statistic: -28.5074, p-value: 3.096206271894725e-49\n",
      "\n",
      "\n",
      "Reject the Null Hypothesis\n",
      "Conclusion : There is SIGNIFICANT difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Setting numpy random seed\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generating normal test scores with same variance for both control groups\n",
    "test_score_control = np.random.normal(loc=70, scale=3, size=50)\n",
    "test_score_experimental = np.random.normal(loc=85, scale=3, size=50)\n",
    "\n",
    "# Creating the dataframe\n",
    "df = pd.DataFrame({'test_score':list(test_score_control)+list(test_score_experimental),\n",
    "                   'group':['control']*50 + ['experimental']*50})\n",
    "\n",
    "# printing the sample dataframe\n",
    "print('Simulated data for test_scores:')\n",
    "print(df.head())\n",
    "print('\\n************************\\n')\n",
    "\n",
    "null_hypothesis = \"There is NO difference in test scores between the control and experimental groups.\"\n",
    "alt_hypothesis = \"There is SIGNIFICANT difference in test scores between the control and experimental groups.\"\n",
    "\n",
    "# Conduct the two-sample t-test\n",
    "control_scores = df[df['group'] == 'control']['test_score']\n",
    "experimental_scores = df[df['group'] == 'experimental']['test_score']\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores, equal_var=True)\n",
    "print(f\"t-statistic: {t_stat:.4f}, p-value: {p_val}\")\n",
    "print('\\n')\n",
    "\n",
    "# Significance value \n",
    "alpha = 0.05\n",
    "if p_val<alpha:\n",
    "    print('Reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {alt_hypothesis}')\n",
    "else:\n",
    "    print('Failed to reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {null_hypothesis}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a4446-ffc0-45f1-a163-89361e4cb27a",
   "metadata": {},
   "source": [
    "#### (12)-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551ce60b-18f1-4023-bd1f-6769f4bc9e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data top 5 rows : \n",
      "   Day    Store        Sales\n",
      "0    0  Store A   933.187150\n",
      "1    1  Store A   950.179048\n",
      "2    2  Store A  1061.857582\n",
      "3    3  Store A  1056.869225\n",
      "4    4  Store A  1135.050948\n",
      "\n",
      "_______________________________\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 51.5040 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n",
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1  group2  meandiff p-adj    lower     upper   reject\n",
      "-----------------------------------------------------------\n",
      "Store A Store B   21.2439 0.6945   -40.881   83.3688  False\n",
      "Store A Store C -207.8078    0.0 -269.9328 -145.6829   True\n",
      "Store B Store C -229.0517    0.0 -291.1766 -166.9268   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# generate sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=1000, scale=100, size=(30,))\n",
    "sales_b = np.random.normal(loc=1050, scale=150, size=(30,))\n",
    "sales_c = np.random.normal(loc=800, scale=80, size=(30,))\n",
    "\n",
    "# create a DataFrame to store the sales data\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "\n",
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_melted.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "# Printing top 5 rows of generated data\n",
    "print('Generated data top 5 rows : ')\n",
    "print(sales_melted.head())\n",
    "\n",
    "print('\\n_______________________________\\n')\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n",
    "\n",
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f21608-bf84-49b3-853d-a48a8ab8c729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
