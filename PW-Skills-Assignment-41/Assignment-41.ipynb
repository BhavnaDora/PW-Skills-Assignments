{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1b2400-8dec-4673-b3ed-e14ef806ba7f",
   "metadata": {},
   "source": [
    "#### (1)-\n",
    "##### Missing values occur in a dataset when some of the information is not stored for a variable. There are 3 mechanisms why missing values occur- \n",
    "- Missing Completely At Random(MCAR)\n",
    "- Missing At Random(MAR)\n",
    "- Missing Not At Random(MNAR)\n",
    "##### It is important to handle missing values because it can cause bias in the results, it can lead to inaccurate predictions and can affect the generalizability of the model.\n",
    "##### The algorithms that are not affected by missing values are KNN, Random Forest, Histogram based gradient boosting algorithm, Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc1b53-93fb-4087-aa68-aea2772616f4",
   "metadata": {},
   "source": [
    "#### (2)-\n",
    "##### We use imputation techniques to handle missing values-\n",
    "- Mean value imputation\n",
    "- Median value imputation\n",
    "- Mode value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594b9e3-3707-4eab-9670-994cf2604f07",
   "metadata": {},
   "source": [
    "#####  1) Mean value imputation-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd0a3fb-b473-4785-bf16-678b1d945743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df= sns.load_dataset(\"titanic\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a371c95-52c9-472e-841f-5c53e614eefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab06d5b-24d9-4049-bf3b-54c78a4ec00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_mean\"]= df[\"age\"].fillna(df[\"age\"].mean())        # the NaN values in the age column are replaced with the mean of the age column and stored in a new column- age_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47eb9c2-7a93-457a-b271-7e6896f1be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_mean   age\n",
       "0    22.000000  22.0\n",
       "1    38.000000  38.0\n",
       "2    26.000000  26.0\n",
       "3    35.000000  35.0\n",
       "4    35.000000  35.0\n",
       "..         ...   ...\n",
       "886  27.000000  27.0\n",
       "887  19.000000  19.0\n",
       "888  29.699118   NaN\n",
       "889  26.000000  26.0\n",
       "890  32.000000  32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"age_mean\", \"age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380459c-30aa-44f4-9ff6-abd584c75e8c",
   "metadata": {},
   "source": [
    "##### 2) Median value imputation-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59da2904-eed5-4873-ad1c-dc2de366341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_median\"]= df[\"age\"].fillna(df[\"age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea1bf37-1544-4ccb-8b33-837dbd5b0eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_median</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_median   age\n",
       "0          22.0  22.0\n",
       "1          38.0  38.0\n",
       "2          26.0  26.0\n",
       "3          35.0  35.0\n",
       "4          35.0  35.0\n",
       "..          ...   ...\n",
       "886        27.0  27.0\n",
       "887        19.0  19.0\n",
       "888        28.0   NaN\n",
       "889        26.0  26.0\n",
       "890        32.0  32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"age_median\", \"age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20754202-1751-4d0f-9167-251c37023577",
   "metadata": {},
   "source": [
    "##### 3) Mode value imputation-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af60045e-b87e-47e5-b49c-135d4ca109b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch  fare embarked  class  \\\n",
       "61          1       1  female  38.0      0      0  80.0      NaN  First   \n",
       "829         1       1  female  62.0      0      0  80.0      NaN  First   \n",
       "\n",
       "       who  adult_male deck embark_town alive  alone  age_mean  age_median  \n",
       "61   woman       False    B         NaN   yes   True      38.0        38.0  \n",
       "829  woman       False    B         NaN   yes   True      62.0        62.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b21258-b33e-4718-afef-0137f564c4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embarked\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086d65bc-42d1-4c28-bfda-03e4748a0e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    S\n",
       "Name: embarked, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"embarked\"].notna()][\"embarked\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb21855c-4fd4-465b-829f-b59b652ea2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_value= df[df[\"embarked\"].notna()][\"embarked\"].mode()[0]\n",
    "mode_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c20a9e-a924-4e23-8e48-398c8780326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embarked_mode\"]= df[\"embarked\"].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633392db-5582-4af0-8e04-046b998ec76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked_mode</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    embarked_mode embarked\n",
       "0               S        S\n",
       "1               C        C\n",
       "2               S        S\n",
       "3               S        S\n",
       "4               S        S\n",
       "..            ...      ...\n",
       "886             S        S\n",
       "887             S        S\n",
       "888             S        S\n",
       "889             C        C\n",
       "890             Q        Q\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"embarked_mode\", \"embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa08505-e691-4bfd-928d-bb60b16eb188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embarked_mode\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddad28c-5272-4197-8c92-d8f8db35aff8",
   "metadata": {},
   "source": [
    "#### (3)-\n",
    "##### Imbalanced dataset has unequal distribution of classes. Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations.\n",
    "##### If we don't handle the imbalanced dataset, then our classifier or model will be biased towards the class with majority data points. The model learns more from biased examples as opposed to the examples in the minority class. One might end up with a scenario where a model assumes that any data you feed it belongs to the majority class. This, as a result, makes a model seem naïve in its predictions, regardless of achieving high accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c871207-694a-4700-ae4e-6e1203172a60",
   "metadata": {},
   "source": [
    "#### (4)-\n",
    "##### Up-sampling is a technique in which we randomly duplicate the observations from the minority class in order to reinforce its signal. Down-sampling is a technique in which we randomly remove observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "##### Example of down-sampling- if we have a dataset containing info about patients who have cancer and who don't have cancer, then the no. of patients who have cancer will be less, so this is an imbalanced dataset and here we should do down sampling of the majority class i.e. the no. of patients who are cancer free and finally have a balanced dataset.\n",
    "##### Example of up-sampling- if we have a dataset containing heights of boys and girls and one class let's say the boys heights' have majority data points, then we can upsample the monority class i.e. girls heights' data points and finally have a balanced daatset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef366a-8176-4233-a8da-c700130d825b",
   "metadata": {},
   "source": [
    "#### (5)-\n",
    "##### Data Augmentation is a method that works much like oversampling. Yet Data Augmentation adds a twist- rather than making exact duplicates of observations in the minority class, you will add small perturbations to the copied data points i.e. create synthetic data based on original data.\n",
    "##### SMOTE(Synthetic Minority Over-sampling Technique) is a technique used in machine learning to address imbalanced datasets where the minority class has significantly fewer instances than the majority class. SMOTE involves generating synthetic instances of the minority class by interpolating between existing instances. So, SMOTE performs data augmentation by creating synthetic data points based on the original data points. The advantage of SMOTE is that you are not generating duplicates, but rather creating synthetic data points that are slightly different from the original data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4aadb-e7c3-4d08-baa8-027d986c6718",
   "metadata": {},
   "source": [
    "#### (6)-\n",
    "##### Outliers are extreme values that differ from most other data points in a dataset. It is important to handle outliers because they can have a big impact on our statistical analyses and skew the results of any hypothesis tests. The mean of the dataset is sensitive to outliers, it shifts drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696176f-af21-441a-b7e1-42c295040f4d",
   "metadata": {},
   "source": [
    "#### (7)-\n",
    "##### We can handle the missing data by deleting those row records or by deleting the columns with null values using the dropna() method. But this results in loss of data, so we follow some imputation techniques like-\n",
    "- 1. Mean value imputation- We replace the null values in the column with the mean value of the column. This method is effective if we have normal distribution of data. \n",
    "- 2. Median value imputation- We replace the null values in the column with the median value of the column. This method is effective if our dataset contains outliers.\n",
    "- 3. Mode value imputation- We replace the null values of a column with categorical data with the mode value.\n",
    "- 4. Random value imputation- We replace the null values of the column with a random value from that column. random value imputation is used when we have MCAR data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c15db-830c-4930-943e-f9aebc486de9",
   "metadata": {},
   "source": [
    "#### (8)-\n",
    "##### Strategies to determine the type of missing data-\n",
    "- MNAR- Using Little's test where we create a new binary variable where missing is coded as 1 and not missing is coded as 0. We compare the mean of another feature for 1's and 0's, if there is significant difference in means we have significant evidence that the data is missing not at random. \n",
    "- MAR- If there is no significant difference between our primary variable of interest and the missing and non-missing values, we have evidence that our data is missing at random.\n",
    "- MCAR- Finally, we compare the means on multiple dependent variables. We can run t-tests and chi-square tests between this variable and other variables in the data set to see if the missingness on this variable is related to the values of other variables. If there is no significant realtion, then the data is missing completely at random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44b069-c486-49da-83ef-4083111a293a",
   "metadata": {},
   "source": [
    "#### (9)-\n",
    "##### Although accuracy is considered to be an important metric for evaluating the performance of a machine learning model, sometimes it can be misleading in case of an imbalanced dataset. In such circumstances the strategies to evaluate the performance of machine learning model on imbalanced dataset involves using other performance metrics such as- \n",
    "- Confusion matrix- A breakdown of predictions into a table showing correct predictions along the diagonal and the types of incorrect predictions made.\n",
    "- Precision- A measure of a classifiers exactness.\n",
    "- Recall- A measure of a classifiers completeness\n",
    "- F1 score- Weighted average of precision and recall\n",
    "- Cohen's kappa- Classification accuracy normalized by the imbalance of the classes in the data.\n",
    "- ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9aee0-1da3-4e36-9e8a-02b437a2c279",
   "metadata": {},
   "source": [
    "#### (10)-\n",
    "##### Our dataset here is imbalanced dataset with majority of customers satisfied with the product and very few not satisfied with the product. So, we can down-sample the majority class using the sklearn library's resample() method. Down sampling involves randomly selecting examples from the majority class to delete from the training dataset.\n",
    "##### First we split the target class into 2 data frames one with majority class another with minority class. Then in the resample function we pass the majority data frame as argument, we set the replace as False- because we want only to reduce the data points of the majority class, the sample size is equal to the size of the minority data frame. This resampled data frame we obtain is then concatenated with the minority data frame and finally we have a dataframe with equal no. of majority and minority class data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e78f4-b522-4033-8b85-6d144283188c",
   "metadata": {},
   "source": [
    "#### (11)-\n",
    "##### Our dataset here is imbalanced dataset with low percentage of occurencs of a rare event. So, we can up-sample the minority class using sklearn library's resample() method. Up sampling involves randomly duplicating examples from the minority class and adding them to the training dataset. \n",
    "##### First we split the target class into 2 data frames one with majority class another with minority class. Then in the resample function we pass the minority data frame as argument, we set the replace as True, the sample size is equal to the size of the majority data frame. This resampled data frame we obtain is then concatenated with the majority data frame and finally we have a dataframe with equal no. of majority and minority class data points. \n",
    "##### Using SMOTE we can up-sample the minority class too. We use the fit_resample() method of SMOTE class. SMOTE involves generating synthetic instances of the minority class by interpolating between existing instances. So, SMOTE performs data augmentation by creating synthetic data points based on the original data points. The advantage of SMOTE is that you are not generating duplicates, but rather creating synthetic data points that are slightly different from the original data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249872c-cd3f-42c9-9a9d-885dab46b40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
